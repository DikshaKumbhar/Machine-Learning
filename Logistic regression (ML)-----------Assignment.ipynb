{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec53b29-766e-4dd2-84c8-bfda44822cce",
   "metadata": {},
   "source": [
    "# Supervised Learning: Regression Models and Performance Metrics|Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350cb0e1-2653-4a3c-aeaa-b8f2b84495b6",
   "metadata": {},
   "source": [
    "**Question 1 : What is Simple Linear Regression (SLR)? Explain its purpose.**\n",
    "- Simple Linear Regression (SLR) is a statistical method used to understand the relationship between two variables — one independent (predictor) variable and one dependent (response) variable.\n",
    "- 🔹 Definition:\n",
    "Simple Linear Regression shows how the dependent variable (Y) changes when the independent variable (X) changes by one unit.\n",
    "It fits a straight line (called a regression line) through the data points to predict the value of Y from X.\n",
    "- 🔹 Mathematical Equation: Y=a+bX+e\n",
    "- Where:\n",
    "- Y = Dependent variable (the one we want to predict)\n",
    "- X = Independent variable (the one we use for prediction)\n",
    "- a = Intercept (value of Y when X = 0)\n",
    "- b = Slope (shows how much Y changes for one unit change in X)\n",
    "- e = Error term (difference between predicted and actual values)\n",
    "\n",
    "### Purpose of Simple Linear Regression:\n",
    "- 1. Prediction:\n",
    "To predict the value of one variable based on another.\n",
    "Example: Predicting a student’s marks (Y) based on study hours (X).\n",
    "\n",
    "- 2. Understanding relationships:\n",
    "To study how strongly two variables are related and whether the relationship is positive or negative.\n",
    "\n",
    "- 3. Trend estimation:\n",
    "To find trends in data — for example, how sales increase with advertising expenditure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e16f17-6577-4354-a085-d47bcde57f8b",
   "metadata": {},
   "source": [
    "**Question 2: What are the key assumptions of Simple Linear Regression?**\n",
    "- 1. Linearity\n",
    "The relationship between the independent variable (X) and the dependent variable (Y) is linear.\n",
    "- This means that the change in Y is proportional to the change in X.\n",
    "- Example: If study hours double, the exam score roughly doubles.\n",
    "\n",
    "- 2. Independence of Errors\n",
    "The residuals (errors) — the differences between actual and predicted values — must be independent of each other.\n",
    "In other words, one observation’s error should not depend on another’s.\n",
    "- Example: Marks of one student should not affect marks of another.\n",
    "\n",
    "- 3. Homoscedasticity (Equal Variance)\n",
    "- The variance of errors should be constant across all values of X.\n",
    "- This means the spread of residuals should remain the same for all levels of X.\n",
    "- If not constant (heteroscedasticity) — predictions become less reliable.\n",
    "\n",
    "- 4. Normality of Errors\n",
    "- The residuals (errors) should follow a normal distribution.\n",
    "- This is important for making valid statistical tests (like t-tests or F-tests).\n",
    "- Example: If you plot a histogram of errors, it should look bell-shaped.\n",
    "\n",
    "- 5. No or Minimal Multicollinearity\n",
    "- In Simple Linear Regression, there’s only one independent variable, so this assumption is automatically met.\n",
    "- (It becomes important in Multiple Linear Regression when you have more than one X variable.)\n",
    "\n",
    "- 6. No Autocorrelation (for time series data)\n",
    "- When data is collected over time, the residuals should not be correlated with each other.\n",
    "- If present (autocorrelation) — it violates the independence assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6bc55f-22f5-41a2-a2a2-29dd5fe63dc9",
   "metadata": {},
   "source": [
    "**Question 3: Write the mathematical equation for a simple linear regression model and\n",
    "explain each term.**\n",
    "- Mathematical Equation of Simple Linear Regression:\n",
    "Y=a+bX+e\n",
    "- 🔹 Explanation of Each Term:\n",
    "- 1. Y (Dependent Variable)\n",
    "- The variable we want to predict or explain.\n",
    "- Y depends on X.\n",
    "- Example: Exam marks (Y)\n",
    "\n",
    "- 2. X (Independent Variable)\n",
    "- The variable used to predict the value of Y.\n",
    "- Example: Study hours (X)\n",
    "\n",
    "- 3. a (Intercept / Constant)\n",
    "- The value of Y when X = 0.\n",
    "- It shows where the regression line crosses the Y-axis.\n",
    "- Example: If a = 30, even with 0 study hours, the expected marks are 30.\n",
    "\n",
    "- 4. b (Slope / Regression Coefficient)\n",
    "- It tells how much Y changes when X increases by 1 unit.\n",
    "- It shows the direction and strength of the relationship.\n",
    "- Example: If b = 5, every 1 extra hour of study increases marks by 5.\n",
    "\n",
    "- 5. e (Error Term / Residual)\n",
    "- The difference between the actual and predicted value of Y.\n",
    "- It represents random factors not explained by X — like luck, question difficulty, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44124cc-cc98-4737-9fee-48aef526a3d1",
   "metadata": {},
   "source": [
    "**Question 4: Provide a real-world example where simple linear regression can be\n",
    "applied.**\n",
    "- Example: Predicting House Prices\n",
    "- Objective: Predict the price of a house (Y) based on its size in square feet (X).\n",
    "- \n",
    "**Step 1: Identify Variables**\n",
    "- Dependent variable (Y): House Price (in dollars) → what we want to predict\n",
    "- Independent variable (X): House Size (in square feet) → predictor\n",
    "- \n",
    "**Step 2: Data Collection**\n",
    "  \n",
    "- Suppose we collect data from several houses:\n",
    "- House Size (sq ft)\tPrice ($)\n",
    "- 1000\t150,000\n",
    "- 1200\t180,000\n",
    "- 1500\t220,000\n",
    "- 1800\t260,000\n",
    "- \n",
    "**Step 3: Apply Simple Linear Regression**\n",
    "- We fit a line through the data to get an equation like:\n",
    "- Price=50,000+100×(Size)\n",
    "\n",
    "**Step 4: Interpretation**\n",
    "- Intercept (a = 50,000): Even a house with 0 sq ft has a base price of $50,000 (fixed costs, land value, etc.)\n",
    "- Slope (b = 100): For every additional square foot, the price increases by $100\n",
    "\n",
    "**Step 5: Prediction**\n",
    "- A house of 1600 sq ft → Predicted Price = 50,000 + 100 × 1600 = $210,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff1efff-9e32-4051-8471-9d33d5f4a22f",
   "metadata": {},
   "source": [
    "**Question 5: What is the method of least squares in linear regression?**\n",
    "- The Method of Least Squares is the most common technique used to fit a line in Simple Linear Regression. It helps us find the best-fitting straight line through the data points.\n",
    "- 🔹 Concept:\n",
    "-In regression, we try to predict Y using X, but actual data points may not lie exactly on a straight line.\n",
    "- The difference between the actual value (Yᵢ) and the predicted value (Ŷᵢ) is called the residual or error (eᵢ):\n",
    "- ei=Yi−Y^i\n",
    "- The Method of Least Squares chooses the line such that the sum of the squares of these errors is minimized:\n",
    "- Minimize i=1∑nei2=i=1∑n(Yi−(a+bXi))2\n",
    "  \n",
    "🔹 Why Squared Errors?\n",
    "- Squaring ensures positive values (so negative and positive errors don’t cancel out).\n",
    "- Squared errors penalize larger errors more, making the fit more accurate.\n",
    "\n",
    "🔹 Steps to Find the Best Line\n",
    "- 1. Start with the regression equation:\n",
    "- Y=a+bX\n",
    "- 2. Calculate slope (b) using:\n",
    "- b=∑(Xi−Xˉ)2∑(Xi−Xˉ)(Yi−Yˉ)\n",
    "- 3. Calculate intercept (a) using:\n",
    "- a=Yˉ−bXˉ\n",
    "- Plug a and b into the regression equation → best-fit line.\n",
    "\n",
    "🔹 Summary\n",
    "- The method of least squares finds the line that minimizes the total squared errors between predicted and actual values.\n",
    "- This gives the most accurate prediction for Y from X in Simple Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a9ffdb-594a-4a4a-8061-9327c3f236f3",
   "metadata": {},
   "source": [
    "**Question 6: What is Logistic Regression? How does it differ from Linear Regression?**\n",
    "- 1. What is Logistic Regression?\n",
    "- Logistic Regression is a statistical method used for predicting a categorical outcome (usually binary: 0 or 1, Yes or No, True or False) based on one or more independent variables.\n",
    "- Unlike linear regression, it predicts probabilities of an event occurring, not a continuous value.\n",
    "- It uses the logistic (sigmoid) function to restrict the output between 0 and 1.\n",
    "\n",
    "Logistic Regression Equation:\n",
    "- P(Y=1)=1+e−(a+bX)1\n",
    "- Where:\n",
    "- P(Y=1) = Probability of the event occurring\n",
    "- a = Intercept\n",
    "- b = Coefficient for X\n",
    "- X = Independent variable\n",
    "- e = Euler’s number (~2.718)\n",
    "- The sigmoid function converts any real-valued number into a probability between 0 and 1.\n",
    "\n",
    "**Linear Regression vs Logistic Regression**\n",
    "- 1. Dependent Variable:\n",
    "- Linear Regression predicts a continuous numeric value (like marks, price, weight).\n",
    "- Logistic Regression predicts a categorical outcome (like yes/no, pass/fail, 0/1).\n",
    "\n",
    "- 2. Equation Form: \n",
    "- Linear Regression uses a straight line equation: \n",
    "- Y=a+bX+e\n",
    "- Logistic Regression uses a sigmoid function: \n",
    "- P(Y=1)=1/(1+e−(a+bX))\n",
    "\n",
    "- 3. Output:\n",
    "- Linear Regression gives a direct numeric value.\n",
    "- Logistic Regression gives a probability between 0 and 1.\n",
    "\n",
    "- 4. Relationship with X:\n",
    "- Linear Regression assumes a linear relationship between X and Y.\n",
    "- Logistic Regression assumes a linear relationship with the log-odds of Y, not with Y itself.\n",
    "\n",
    "- 5. Error Minimization:\n",
    "- Linear Regression minimizes sum of squared errors.\n",
    "- Logistic Regression maximizes the likelihood function using Maximum Likelihood Estimation.\n",
    "\n",
    "- 6. Use Case Examples:\n",
    "- Linear Regression: Predicting house prices from size, predicting marks from study hours.\n",
    "- Logistic Regression: Predicting whether a student will pass/fail, whether a customer will buy a product (yes/no), predicting disease (yes/no)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134179b-39f2-4865-b1b8-ae4e5ee04c32",
   "metadata": {},
   "source": [
    "**Question 7: Name and briefly describe three common evaluation metrics for regression\n",
    "models.**\n",
    "- 1. Mean Absolute Error (MAE)\n",
    "\n",
    "Definition: It measures the average of the absolute differences between predicted and actual values.\n",
    "\n",
    "Formula:\n",
    "-  MAE=n1i=1∑n∣yi−y^i∣\n",
    "- Meaning: Lower MAE means better performance. It shows how far predictions are from the actual values on average.\n",
    "\n",
    "- 2. Mean Squared Error (MSE)\n",
    "- Definition: It measures the average of the squared differences between predicted and actual values.\n",
    "\n",
    "- Formula:\n",
    "- MSE=n1i=1∑n(yi−y^i)2\n",
    "Meaning: Squaring penalizes larger errors more heavily, so MSE is sensitive to outliers.\n",
    "\n",
    "3. R-squared (Coefficient of Determination)\n",
    "- Definition: It indicates how well the regression model explains the variability of the target variable.\n",
    "- Meaning: R² ranges from 0 to 1, where 1 means perfect prediction and 0 means the model explains none of the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8e234b-fc36-4cc3-8723-c216470d6dab",
   "metadata": {},
   "source": [
    "**Question 8: What is the purpose of the R-squared metric in regression analysis?**\n",
    "- Definition:\n",
    "- R-squared, also known as the coefficient of determination, is a statistical measure that represents the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
    "- It is denoted by R² and is expressed as a value between 0 and 1.\n",
    "  \n",
    "**Purpose of R-squared:**\n",
    "\n",
    "- 1. Measures Goodness of Fit:\n",
    "- R² tells how well the regression model fits the observed data.\n",
    "A higher R² value indicates that the model fits the data more accurately.\n",
    "\n",
    "- 2. Explains Variability:\n",
    "- It shows the percentage of the total variation in the dependent variable that is explained by the independent variables.\n",
    "For example, R² = 0.80 means 80% of the variability in the output is explained by the model.\n",
    "\n",
    "- 3. Model Performance Comparison:\n",
    "- R² helps in comparing different regression models.\n",
    "The model with a higher R² value is generally considered better (provided other assumptions are met).\n",
    "\n",
    "- 4. Indicator of Prediction Accuracy:\n",
    "- A higher R² usually indicates better predictive accuracy, meaning the predicted values are close to the actual values.\n",
    "\n",
    "- 5. Assists in Model Validation:\n",
    "- It helps analysts and researchers determine whether the independent variables used in the model are effective in explaining the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6702ede8-a976-4e61-9d92-eec4d057a893",
   "metadata": {},
   "source": [
    "**Question 9: Write Python code to fit a simple linear regression model using scikit-learn\n",
    "and print the slope and intercept.\n",
    "(Include your Python code and output in the code box below.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f6f312-58f2-49d9-871a-07bdcaf21665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope (Coefficient): 0.6\n",
      "Intercept: 2.2\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Example data (independent variable X and dependent variable y)\n",
    "# X should be in 2D shape\n",
    "X = [[1], [2], [3], [4], [5]]      # Input / Independent variable\n",
    "y = [2, 4, 5, 4, 5]                # Output / Dependent variable\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X, y)\n",
    "\n",
    "# Print the slope (coefficient) and intercept\n",
    "print(\"Slope (Coefficient):\", model.coef_[0])\n",
    "print(\"Intercept:\", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63479de-401d-43e8-bccc-888b46f23a1c",
   "metadata": {},
   "source": [
    "**Question 10: How do you interpret the coefficients in a simple linear regression model?**\n",
    "- A Simple Linear Regression model helps to understand the relationship between a dependent variable (Y) and a single independent variable (X).\n",
    "It estimates how much Y changes when X changes by one unit.\n",
    "- The model is represented as:\n",
    "- Where:\n",
    "- Y=b0+b1X+ε\n",
    "- Y → Dependent (target) variable\n",
    "- X → Independent (predictor) variable\n",
    "- b₀ → Intercept (constant term)\n",
    "- b₁ → Slope or coefficient of X\n",
    "- ε → Random error term\n",
    "\n",
    "- 2. Coefficients in the Model\n",
    "- There are two main coefficients in a simple linear regression model:\n",
    "- (a) Intercept (b₀):\n",
    "- The intercept represents the predicted value of Y when X = 0.\n",
    "- It is the point where the regression line crosses the Y-axis.\n",
    "- It shows the baseline value of the dependent variable before any effect of X is applied.\n",
    "- Example: If the regression equation is\n",
    "- Y=50+5X\n",
    "- then when X = 0, the predicted Y = 50.\n",
    "- This means the baseline output value (Y) is 50 before considering any effect of X.\n",
    "\n",
    "- (b) Slope (b₁):\n",
    "- The slope tells how much Y changes for a one-unit increase in X.\n",
    "- It represents the rate of change between the dependent and independent variable.\n",
    "- If b₁ is positive, Y increases as X increases (direct relationship).\n",
    "- If b₁ is negative, Y decreases as X increases (inverse relationship).\n",
    "- Example:\n",
    "- In the same equation : Y=50+5X\n",
    "- the slope b₁ = 5 means that for every 1-unit increase in X, the value of Y increases by 5 units.\n",
    "\n",
    "- 3. Real-life Example\n",
    "- Suppose we build a regression model to predict student test scores (Y) based on hours studied (X).\n",
    "- The regression equation is : Y=35+6X\n",
    "- Interpretation:\n",
    "- Intercept (35): A student who studies 0 hours is expected to score 35 marks.\n",
    "- Slope (6): For each additional hour of study, the student’s score increases by 6 marks on average."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
