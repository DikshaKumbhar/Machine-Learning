{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec53b29-766e-4dd2-84c8-bfda44822cce",
   "metadata": {},
   "source": [
    "# Supervised Learning: Regression Models and Performance Metrics|Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350cb0e1-2653-4a3c-aeaa-b8f2b84495b6",
   "metadata": {},
   "source": [
    "**Question 1 : What is Simple Linear Regression (SLR)? Explain its purpose.**\n",
    "- Simple Linear Regression (SLR) is a statistical method used to understand the relationship between two variables ‚Äî one independent (predictor) variable and one dependent (response) variable.\n",
    "- üîπ Definition:\n",
    "Simple Linear Regression shows how the dependent variable (Y) changes when the independent variable (X) changes by one unit.\n",
    "It fits a straight line (called a regression line) through the data points to predict the value of Y from X.\n",
    "- üîπ Mathematical Equation: Y=a+bX+e\n",
    "- Where:\n",
    "- Y = Dependent variable (the one we want to predict)\n",
    "- X = Independent variable (the one we use for prediction)\n",
    "- a = Intercept (value of Y when X = 0)\n",
    "- b = Slope (shows how much Y changes for one unit change in X)\n",
    "- e = Error term (difference between predicted and actual values)\n",
    "\n",
    "### Purpose of Simple Linear Regression:\n",
    "- 1. Prediction:\n",
    "To predict the value of one variable based on another.\n",
    "Example: Predicting a student‚Äôs marks (Y) based on study hours (X).\n",
    "\n",
    "- 2. Understanding relationships:\n",
    "To study how strongly two variables are related and whether the relationship is positive or negative.\n",
    "\n",
    "- 3. Trend estimation:\n",
    "To find trends in data ‚Äî for example, how sales increase with advertising expenditure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e16f17-6577-4354-a085-d47bcde57f8b",
   "metadata": {},
   "source": [
    "**Question 2: What are the key assumptions of Simple Linear Regression?**\n",
    "- 1. Linearity\n",
    "The relationship between the independent variable (X) and the dependent variable (Y) is linear.\n",
    "- This means that the change in Y is proportional to the change in X.\n",
    "- Example: If study hours double, the exam score roughly doubles.\n",
    "\n",
    "- 2. Independence of Errors\n",
    "The residuals (errors) ‚Äî the differences between actual and predicted values ‚Äî must be independent of each other.\n",
    "In other words, one observation‚Äôs error should not depend on another‚Äôs.\n",
    "- Example: Marks of one student should not affect marks of another.\n",
    "\n",
    "- 3. Homoscedasticity (Equal Variance)\n",
    "- The variance of errors should be constant across all values of X.\n",
    "- This means the spread of residuals should remain the same for all levels of X.\n",
    "- If not constant (heteroscedasticity) ‚Äî predictions become less reliable.\n",
    "\n",
    "- 4. Normality of Errors\n",
    "- The residuals (errors) should follow a normal distribution.\n",
    "- This is important for making valid statistical tests (like t-tests or F-tests).\n",
    "- Example: If you plot a histogram of errors, it should look bell-shaped.\n",
    "\n",
    "- 5. No or Minimal Multicollinearity\n",
    "- In Simple Linear Regression, there‚Äôs only one independent variable, so this assumption is automatically met.\n",
    "- (It becomes important in Multiple Linear Regression when you have more than one X variable.)\n",
    "\n",
    "- 6. No Autocorrelation (for time series data)\n",
    "- When data is collected over time, the residuals should not be correlated with each other.\n",
    "- If present (autocorrelation) ‚Äî it violates the independence assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6bc55f-22f5-41a2-a2a2-29dd5fe63dc9",
   "metadata": {},
   "source": [
    "**Question 3: Write the mathematical equation for a simple linear regression model and\n",
    "explain each term.**\n",
    "- Mathematical Equation of Simple Linear Regression:\n",
    "Y=a+bX+e\n",
    "- üîπ Explanation of Each Term:\n",
    "- 1. Y (Dependent Variable)\n",
    "- The variable we want to predict or explain.\n",
    "- Y depends on X.\n",
    "- Example: Exam marks (Y)\n",
    "\n",
    "- 2. X (Independent Variable)\n",
    "- The variable used to predict the value of Y.\n",
    "- Example: Study hours (X)\n",
    "\n",
    "- 3. a (Intercept / Constant)\n",
    "- The value of Y when X = 0.\n",
    "- It shows where the regression line crosses the Y-axis.\n",
    "- Example: If a = 30, even with 0 study hours, the expected marks are 30.\n",
    "\n",
    "- 4. b (Slope / Regression Coefficient)\n",
    "- It tells how much Y changes when X increases by 1 unit.\n",
    "- It shows the direction and strength of the relationship.\n",
    "- Example: If b = 5, every 1 extra hour of study increases marks by 5.\n",
    "\n",
    "- 5. e (Error Term / Residual)\n",
    "- The difference between the actual and predicted value of Y.\n",
    "- It represents random factors not explained by X ‚Äî like luck, question difficulty, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44124cc-cc98-4737-9fee-48aef526a3d1",
   "metadata": {},
   "source": [
    "**Question 4: Provide a real-world example where simple linear regression can be\n",
    "applied.**\n",
    "- Example: Predicting House Prices\n",
    "- Objective: Predict the price of a house (Y) based on its size in square feet (X).\n",
    "- \n",
    "**Step 1: Identify Variables**\n",
    "- Dependent variable (Y): House Price (in dollars) ‚Üí what we want to predict\n",
    "- Independent variable (X): House Size (in square feet) ‚Üí predictor\n",
    "- \n",
    "**Step 2: Data Collection**\n",
    "  \n",
    "- Suppose we collect data from several houses:\n",
    "- House Size (sq ft)\tPrice ($)\n",
    "- 1000\t150,000\n",
    "- 1200\t180,000\n",
    "- 1500\t220,000\n",
    "- 1800\t260,000\n",
    "- \n",
    "**Step 3: Apply Simple Linear Regression**\n",
    "- We fit a line through the data to get an equation like:\n",
    "- Price=50,000+100√ó(Size)\n",
    "\n",
    "**Step 4: Interpretation**\n",
    "- Intercept (a = 50,000): Even a house with 0 sq ft has a base price of $50,000 (fixed costs, land value, etc.)\n",
    "- Slope (b = 100): For every additional square foot, the price increases by $100\n",
    "\n",
    "**Step 5: Prediction**\n",
    "- A house of 1600 sq ft ‚Üí Predicted Price = 50,000 + 100 √ó 1600 = $210,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff1efff-9e32-4051-8471-9d33d5f4a22f",
   "metadata": {},
   "source": [
    "**Question 5: What is the method of least squares in linear regression?**\n",
    "- The Method of Least Squares is the most common technique used to fit a line in Simple Linear Regression. It helps us find the best-fitting straight line through the data points.\n",
    "- üîπ Concept:\n",
    "-In regression, we try to predict Y using X, but actual data points may not lie exactly on a straight line.\n",
    "- The difference between the actual value (Y·µ¢) and the predicted value (≈∂·µ¢) is called the residual or error (e·µ¢):\n",
    "- ei=Yi‚àíY^i\n",
    "- The Method of Least Squares chooses the line such that the sum of the squares of these errors is minimized:\n",
    "- Minimize¬†i=1‚àënei2=i=1‚àën(Yi‚àí(a+bXi))2\n",
    "  \n",
    "üîπ Why Squared Errors?\n",
    "- Squaring ensures positive values (so negative and positive errors don‚Äôt cancel out).\n",
    "- Squared errors penalize larger errors more, making the fit more accurate.\n",
    "\n",
    "üîπ Steps to Find the Best Line\n",
    "- 1. Start with the regression equation:\n",
    "- Y=a+bX\n",
    "- 2. Calculate slope (b) using:\n",
    "- b=‚àë(Xi‚àíXÀâ)2‚àë(Xi‚àíXÀâ)(Yi‚àíYÀâ)\n",
    "- 3. Calculate intercept (a) using:\n",
    "- a=YÀâ‚àíbXÀâ\n",
    "- Plug a and b into the regression equation ‚Üí best-fit line.\n",
    "\n",
    "üîπ Summary\n",
    "- The method of least squares finds the line that minimizes the total squared errors between predicted and actual values.\n",
    "- This gives the most accurate prediction for Y from X in Simple Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a9ffdb-594a-4a4a-8061-9327c3f236f3",
   "metadata": {},
   "source": [
    "**Question 6: What is Logistic Regression? How does it differ from Linear Regression?**\n",
    "- 1. What is Logistic Regression?\n",
    "- Logistic Regression is a statistical method used for predicting a categorical outcome (usually binary: 0 or 1, Yes or No, True or False) based on one or more independent variables.\n",
    "- Unlike linear regression, it predicts probabilities of an event occurring, not a continuous value.\n",
    "- It uses the logistic (sigmoid) function to restrict the output between 0 and 1.\n",
    "\n",
    "Logistic Regression Equation:\n",
    "- P(Y=1)=1+e‚àí(a+bX)1\n",
    "- Where:\n",
    "- P(Y=1) = Probability of the event occurring\n",
    "- a = Intercept\n",
    "- b = Coefficient for X\n",
    "- X = Independent variable\n",
    "- e = Euler‚Äôs number (~2.718)\n",
    "- The sigmoid function converts any real-valued number into a probability between 0 and 1.\n",
    "\n",
    "**Linear Regression vs Logistic Regression**\n",
    "- 1. Dependent Variable:\n",
    "- Linear Regression predicts a continuous numeric value (like marks, price, weight).\n",
    "- Logistic Regression predicts a categorical outcome (like yes/no, pass/fail, 0/1).\n",
    "\n",
    "- 2. Equation Form: \n",
    "- Linear Regression uses a straight line equation: \n",
    "- Y=a+bX+e\n",
    "- Logistic Regression uses a sigmoid function: \n",
    "- P(Y=1)=1/(1+e‚àí(a+bX))\n",
    "\n",
    "- 3. Output:\n",
    "- Linear Regression gives a direct numeric value.\n",
    "- Logistic Regression gives a probability between 0 and 1.\n",
    "\n",
    "- 4. Relationship with X:\n",
    "- Linear Regression assumes a linear relationship between X and Y.\n",
    "- Logistic Regression assumes a linear relationship with the log-odds of Y, not with Y itself.\n",
    "\n",
    "- 5. Error Minimization:\n",
    "- Linear Regression minimizes sum of squared errors.\n",
    "- Logistic Regression maximizes the likelihood function using Maximum Likelihood Estimation.\n",
    "\n",
    "- 6. Use Case Examples:\n",
    "- Linear Regression: Predicting house prices from size, predicting marks from study hours.\n",
    "- Logistic Regression: Predicting whether a student will pass/fail, whether a customer will buy a product (yes/no), predicting disease (yes/no)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134179b-39f2-4865-b1b8-ae4e5ee04c32",
   "metadata": {},
   "source": [
    "**Question 7: Name and briefly describe three common evaluation metrics for regression\n",
    "models.**\n",
    "- 1. Mean Absolute Error (MAE)\n",
    "\n",
    "Definition: It measures the average of the absolute differences between predicted and actual values.\n",
    "\n",
    "Formula:\n",
    "-  MAE=n1i=1‚àën‚à£yi‚àíy^i‚à£\n",
    "- Meaning: Lower MAE means better performance. It shows how far predictions are from the actual values on average.\n",
    "\n",
    "- 2. Mean Squared Error (MSE)\n",
    "- Definition: It measures the average of the squared differences between predicted and actual values.\n",
    "\n",
    "- Formula:\n",
    "- MSE=n1i=1‚àën(yi‚àíy^i)2\n",
    "Meaning: Squaring penalizes larger errors more heavily, so MSE is sensitive to outliers.\n",
    "\n",
    "3. R-squared (Coefficient of Determination)\n",
    "- Definition: It indicates how well the regression model explains the variability of the target variable.\n",
    "- Meaning: R¬≤ ranges from 0 to 1, where 1 means perfect prediction and 0 means the model explains none of the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8e234b-fc36-4cc3-8723-c216470d6dab",
   "metadata": {},
   "source": [
    "**Question 8: What is the purpose of the R-squared metric in regression analysis?**\n",
    "- Definition:\n",
    "- R-squared, also known as the coefficient of determination, is a statistical measure that represents the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
    "- It is denoted by R¬≤ and is expressed as a value between 0 and 1.\n",
    "  \n",
    "**Purpose of R-squared:**\n",
    "\n",
    "- 1. Measures Goodness of Fit:\n",
    "- R¬≤ tells how well the regression model fits the observed data.\n",
    "A higher R¬≤ value indicates that the model fits the data more accurately.\n",
    "\n",
    "- 2. Explains Variability:\n",
    "- It shows the percentage of the total variation in the dependent variable that is explained by the independent variables.\n",
    "For example, R¬≤ = 0.80 means 80% of the variability in the output is explained by the model.\n",
    "\n",
    "- 3. Model Performance Comparison:\n",
    "- R¬≤ helps in comparing different regression models.\n",
    "The model with a higher R¬≤ value is generally considered better (provided other assumptions are met).\n",
    "\n",
    "- 4. Indicator of Prediction Accuracy:\n",
    "- A higher R¬≤ usually indicates better predictive accuracy, meaning the predicted values are close to the actual values.\n",
    "\n",
    "- 5. Assists in Model Validation:\n",
    "- It helps analysts and researchers determine whether the independent variables used in the model are effective in explaining the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6702ede8-a976-4e61-9d92-eec4d057a893",
   "metadata": {},
   "source": [
    "**Question 9: Write Python code to fit a simple linear regression model using scikit-learn\n",
    "and print the slope and intercept.\n",
    "(Include your Python code and output in the code box below.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f6f312-58f2-49d9-871a-07bdcaf21665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope (Coefficient): 0.6\n",
      "Intercept: 2.2\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Example data (independent variable X and dependent variable y)\n",
    "# X should be in 2D shape\n",
    "X = [[1], [2], [3], [4], [5]]      # Input / Independent variable\n",
    "y = [2, 4, 5, 4, 5]                # Output / Dependent variable\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X, y)\n",
    "\n",
    "# Print the slope (coefficient) and intercept\n",
    "print(\"Slope (Coefficient):\", model.coef_[0])\n",
    "print(\"Intercept:\", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63479de-401d-43e8-bccc-888b46f23a1c",
   "metadata": {},
   "source": [
    "**Question 10: How do you interpret the coefficients in a simple linear regression model?**\n",
    "- A Simple Linear Regression model helps to understand the relationship between a dependent variable (Y) and a single independent variable (X).\n",
    "It estimates how much Y changes when X changes by one unit.\n",
    "- The model is represented as:\n",
    "- Where:\n",
    "- Y=b0+b1X+Œµ\n",
    "- Y ‚Üí Dependent (target) variable\n",
    "- X ‚Üí Independent (predictor) variable\n",
    "- b‚ÇÄ ‚Üí Intercept (constant term)\n",
    "- b‚ÇÅ ‚Üí Slope or coefficient of X\n",
    "- Œµ ‚Üí Random error term\n",
    "\n",
    "- 2. Coefficients in the Model\n",
    "- There are two main coefficients in a simple linear regression model:\n",
    "- (a) Intercept (b‚ÇÄ):\n",
    "- The intercept represents the predicted value of Y when X = 0.\n",
    "- It is the point where the regression line crosses the Y-axis.\n",
    "- It shows the baseline value of the dependent variable before any effect of X is applied.\n",
    "- Example: If the regression equation is\n",
    "- Y=50+5X\n",
    "- then when X = 0, the predicted Y = 50.\n",
    "- This means the baseline output value (Y) is 50 before considering any effect of X.\n",
    "\n",
    "- (b) Slope (b‚ÇÅ):\n",
    "- The slope tells how much Y changes for a one-unit increase in X.\n",
    "- It represents the rate of change between the dependent and independent variable.\n",
    "- If b‚ÇÅ is positive, Y increases as X increases (direct relationship).\n",
    "- If b‚ÇÅ is negative, Y decreases as X increases (inverse relationship).\n",
    "- Example:\n",
    "- In the same equation : Y=50+5X\n",
    "- the slope b‚ÇÅ = 5 means that for every 1-unit increase in X, the value of Y increases by 5 units.\n",
    "\n",
    "- 3. Real-life Example\n",
    "- Suppose we build a regression model to predict student test scores (Y) based on hours studied (X).\n",
    "- The regression equation is : Y=35+6X\n",
    "- Interpretation:\n",
    "- Intercept (35): A student who studies 0 hours is expected to score 35 marks.\n",
    "- Slope (6): For each additional hour of study, the student‚Äôs score increases by 6 marks on average."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
